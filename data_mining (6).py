# -*- coding: utf-8 -*-
"""data_mining.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QbgNmIbl8xOpUbUKuau2WZ6YwxhfVami
"""

import pandas as pd
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
import pandas as pd
import numpy as np

# Φόρτωση του αρχείου Excel στο Colab
from google.colab import files
uploaded = files.upload()

# Φόρτωση των δεδομένων σε ένα DataFrame
df = pd.read_excel('movies.xlsx')

# Load the CSV file into a DataFrame
df2 = pd.read_csv('IMDB-Movie-Data.csv')

# Φόρτωση των δεδομένων σε ένα DataFrame
df3 = pd.read_excel('movies_test _anon.xlsx')

# Increase the maximum number of displayed columns
pd.set_option('display.max_columns', 30)  # Set to the desired number of columns

df.head(1)

df2.head(50)

df3.head(10)

df['Release Date (US)'] = pd.to_datetime(df['Release Date (US)'], errors='coerce')

print(df.columns)

df = df.drop(['Worldwide Gross ($million)', 'Worldwide Gross', 'Oscar Detail'], axis=1)

# Display the DataFrame
print(df.dtypes)

# Fill missing values in 'IMDb Rating' with values from 'Rating'
df['IMDb Rating'].fillna(df2['Rating'], inplace=True)

#B1

# Fill missing values in the 'Oscar Winners' column with a default value (e.g., 0)
df['Oscar Winners'].fillna(0, inplace=True)

# Convert non-numeric values to 1 (assuming 'Oscar winner' means 1)
df['Oscar Winners'] = df['Oscar Winners'].apply(lambda x: 1 if x == 'Oscar winner' else x)

# Convert the target variable 'Oscar Winners' to numeric (1 or 0)
df['Oscar Winners'] = pd.to_numeric(df['Oscar Winners'], errors='coerce').fillna(0).astype(int)

# Drop rows with missing values in the target variable
df = df.dropna(subset=['Oscar Winners'])

# Separate features (X) and target variable (y)
X = df.drop(['Oscar Winners'], axis=1)
y = df['Oscar Winners']

# Handle missing values
X.fillna(0, inplace=True)  # replace 0 with an appropriate value or use a method like mean()

# Replace non-numeric values with 0 in X
X = X.apply(pd.to_numeric, errors='coerce').fillna(0)

# Encode categorical columns
categorical_columns = ['Film', 'Script Type', 'Primary Genre', 'Genre']
X_encoded = pd.get_dummies(X, columns=categorical_columns)


# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)

# Use a Random Forest Classifier with balanced class weights
classifier = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')
classifier.fit(X_train, y_train)

# Save the trained model for future use
import joblib
joblib.dump(classifier, 'oscar_prediction_model.joblib')


# Make predictions on the test set
y_pred = classifier.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print(f'Accuracy: {accuracy:.2f}')

# Display classification report
print(classification_report(y_test, y_pred))

#Β2

df3 = pd.read_excel('movies_test _anon.xlsx')

# Add a placeholder column 'Oscar Winners' with NaN values
df3['Oscar Winners'] = np.nan

# Preprocess the unknown dataset in a similar way as the training dataset
df3['Release Date (US)'] = pd.to_datetime(df3['Release Date (US)'], errors='coerce')

# Drop unnecessary columns
columns_to_drop = ['Worldwide Gross', 'Worldwide Gross ($million)']
df3 = df3.drop(columns=columns_to_drop, axis=1)

# Convert the target variable 'Oscar Winners' to numeric (1 or 0)
df3['Oscar Winners'] = pd.to_numeric(df3['Oscar Winners'], errors='coerce').fillna(0).astype(int)

# Separate features (X_unknown) from the unknown dataset
X_unknown = df3.drop(['Oscar Winners'], axis=1)

# Handle missing values in X_unknown
X_unknown.fillna(0, inplace=True)  # replace 0 with an appropriate value or use a method like mean()

# Replace non-numeric values with 0 in X_unknown
X_unknown = X_unknown.apply(pd.to_numeric, errors='coerce').fillna(0)

# Encode categorical columns in X_unknown
X_unknown_encoded = pd.get_dummies(X_unknown, columns=categorical_columns)

# Ensure the same columns are present in both X_encoded and X_unknown_encoded
common_columns = set(X_encoded.columns) & set(X_unknown_encoded.columns)

# Reorder columns in X_unknown_encoded to match the order in X_encoded
X_unknown_encoded = X_unknown_encoded.reindex(columns=list(X_encoded.columns), fill_value=0)

# Ensure feature names match the training set
missing_features = set(X_encoded.columns) - set(X_unknown_encoded.columns)
for feature in missing_features:
    X_unknown_encoded[feature] = 0

# Only select the relevant features used during training
X_unknown_encoded = X_unknown_encoded[list(X_encoded.columns)]

# Load the trained model
model = joblib.load('oscar_prediction_model.joblib')

# Make predictions on the unknown dataset using the loaded model
y_unknown_pred = model.predict(X_unknown_encoded)

# Update the 'Oscar Winners' column with the predicted values
df3['Oscar Winners'] = y_unknown_pred

# Display the first 100 rows of the updated DataFrame
print(df3[['ID', 'Oscar Winners']])

df3['Oscar Winners'].head(60)

print(df['Oscar Winners'].value_counts())

feature_importances = pd.DataFrame({'feature': X_encoded.columns, 'importance': classifier.feature_importances_})
print(feature_importances.sort_values(by='importance', ascending=False))

print(df3['Oscar Winners'].value_counts())

#Γ

from sklearn.cluster import KMeans
import matplotlib.pyplot as plt

# Choose the number of clusters
num_clusters = 10

# Initialize the KMeans model
kmeans = KMeans(n_clusters=num_clusters, random_state=42)

# Fit the model to the data
clusters = kmeans.fit_predict(X_encoded)

# Add the cluster information to the original DataFrame
df['Cluster'] = clusters

# Display the number of movies in each cluster
print(df['Cluster'].value_counts())

# Analyze the clusters
for cluster_id in range(num_clusters):
    cluster_data = df[df['Cluster'] == cluster_id]
    print(f'\nCluster {cluster_id + 1}:')
    print(cluster_data[['Film', 'Year', 'Primary Genre', 'Genre', 'IMDb Rating', 'Oscar Winners']])

# Visualize the clusters
plt.scatter(X_encoded['IMDb Rating'], X_encoded['Opening Weekend'], c=clusters, cmap='viridis')
plt.title('K-means Clustering')
plt.xlabel('IMDb Rating')
plt.ylabel('Opening Weekend')
plt.show()

from sklearn.metrics import silhouette_score

# Calculate the Silhouette Score
silhouette_avg = silhouette_score(X_encoded, clusters)
print(f"Silhouette Score: {silhouette_avg}")

from sklearn.cluster import AgglomerativeClustering
import matplotlib.pyplot as plt

# Choose the number of clusters
num_clusters = 10

# Initialize the AgglomerativeClustering model
agg_clustering = AgglomerativeClustering(n_clusters=num_clusters)

# Fit the model to the data
clusters = agg_clustering.fit_predict(X_encoded)

# Add the cluster information to the original DataFrame
df['Cluster'] = clusters

# Display the number of movies in each cluster
print(df['Cluster'].value_counts())

# Analyze the clusters
for cluster_id in range(num_clusters):
    cluster_data = df[df['Cluster'] == cluster_id]
    print(f'\nCluster {cluster_id + 1}:')
    print(cluster_data[['Film', 'Year', 'Primary Genre', 'Genre', 'IMDb Rating', 'Domestic Gross', 'Oscar Winners']])

# Visualize the clusters
plt.scatter(X_encoded['IMDb Rating'], X_encoded['Opening Weekend'], c=clusters, cmap='viridis')
plt.title('Hierarchical Clustering')
plt.xlabel('IMDb Rating')
plt.ylabel('Opening Weekend')
plt.show()

from sklearn.cluster import DBSCAN
import matplotlib.pyplot as plt

# Choose the epsilon (eps) and minimum samples (min_samples) parameters for DBSCAN
eps = 0.5
min_samples = 5

# Initialize the DBSCAN model
dbscan = DBSCAN(eps=eps, min_samples=min_samples)

# Fit the model to the data
clusters = dbscan.fit_predict(X_encoded)

# Add the cluster information to the original DataFrame
df['Cluster'] = clusters

# Display the number of movies in each cluster
print(df['Cluster'].value_counts())

# Analyze the clusters
for cluster_id in set(clusters):
    if cluster_id == -1:
        cluster_data = df[df['Cluster'] == cluster_id]
    else:
        cluster_data = df[df['Cluster'] == cluster_id + 1]  # DBSCAN assigns -1 for noise, so we adjust cluster_id
    print(f'\nCluster {cluster_id}:')
    print(cluster_data[['Film', 'Year', 'Primary Genre', 'Genre', 'IMDb Rating', 'Domestic Gross', 'Oscar Winners']])

# Visualize the clusters
plt.scatter(X_encoded['IMDb Rating'], X_encoded['Opening Weekend'], c=clusters, cmap='viridis')
plt.title('DBSCAN Clustering')
plt.xlabel('IMDb Rating')
plt.ylabel('Opening Weekend')
plt.show()

from sklearn.cluster import MeanShift
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt


# Standardize the data
scaler = StandardScaler()
X_cluster_scaled = scaler.fit_transform(X_encoded)

# Initialize the MeanShift model
mean_shift_clustering = MeanShift()

# Fit the model to the scaled data
clusters = mean_shift_clustering.fit_predict(X_cluster_scaled)

# Add the cluster information to the original DataFrame
df['Cluster'] = clusters

# Display the number of movies in each cluster
print(df['Cluster'].value_counts())

# Analyze the clusters
for cluster_id in set(clusters):
    cluster_data = df[df['Cluster'] == cluster_id]
    print(f'\nCluster {cluster_id}:')
    print(cluster_data[['Film', 'Year', 'Primary Genre', 'Genre', 'IMDb Rating', 'Domestic Gross', 'Oscar Winners']])

# Visualize the clusters
plt.scatter(X_cluster_scaled[:, 0], X_cluster_scaled[:, 1], c=clusters, cmap='viridis')
plt.title('Mean Shift Clustering')
plt.xlabel('Standardized IMDb Rating')
plt.ylabel('Standardized Opening Weekend')
plt.show()

from sklearn.metrics import adjusted_rand_score
# Calculate adjusted_rand_score to evaluate the clustering performance for Oscar winners
ari_score = adjusted_rand_score(df['Oscar Winners'], clusters)
print(f'Adjusted Rand Score: {ari_score}')

# Εντοπισμός των δύο πιο πολυπληθών ομάδων
top_clusters = df['Cluster'].value_counts().nlargest(2).index

# Εκτύπωση πληροφοριών για τις δύο πιο πολυπληθείς ομάδες
for cluster_id in top_clusters:
    cluster_data = df[df['Cluster'] == cluster_id]
    print(f'\nCluster {cluster_id}:')
    print(cluster_data[['Film', 'Year', 'Primary Genre', 'Genre', 'IMDb Rating', 'Oscar Winners']])

# Εντοπισμός της ομάδα με τις ταινίες που έχουν κερδίσει βραβείο Oscar
oscar_winner_group = df[df['Oscar Winners'] == 1]

# Προβολή περιγραφής της ομάδας
print("Ομάδα με Ταινίες που Κέρδισαν Βραβείο Oscar:")
print(oscar_winner_group.describe())


print(oscar_winner_group[['Film', 'Oscar Winners']])