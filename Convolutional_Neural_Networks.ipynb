{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYJsMI7t9pX2",
        "outputId": "05b5f5d7-7636-43a2-8ba2-736b1b4f63a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!cp '/content/drive/MyDrive/dermoscopy_classification.tar.gz' .\n",
        "!tar -xf dermoscopy_classification.tar.gz\n",
        "data_dir = '/content/dermoscopy_classification'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "\n",
        "class MLProject2Dataset(Dataset):\n",
        "    def __init__(self, data_dir, metadata_fname='metadata.csv', transform=None):\n",
        "        self.data_dir = data_dir\n",
        "        self.transform = transform\n",
        "\n",
        "\n",
        "        # Load metadata\n",
        "        metadata_path = os.path.join(data_dir, metadata_fname)\n",
        "        metadata = pd.read_csv(metadata_path)\n",
        "        metadata['dx'] = pd.Categorical(metadata['dx']).codes\n",
        "\n",
        "        num_classes = metadata['dx'].nunique()\n",
        "\n",
        "        # Create dataframe with image paths and labels\n",
        "        image_paths = []\n",
        "        for part_dir in os.listdir(data_dir):\n",
        "            part_path = os.path.join(data_dir, part_dir)\n",
        "            if os.path.isdir(part_path):\n",
        "                for f in os.listdir(part_path):\n",
        "                    if f.endswith('.jpg'):\n",
        "                        image_paths.append(os.path.join(part_path, f))\n",
        "\n",
        "        image_ids = [os.path.splitext(os.path.basename(f))[0] for f in image_paths]\n",
        "\n",
        "        # Create dataframe with image paths and labels\n",
        "        image_df = pd.DataFrame({'image_id': image_ids, 'path': image_paths})\n",
        "\n",
        "        # Merge dataframes on 'image_id'\n",
        "        self.data_df = pd.merge(image_df, metadata, on='image_id')\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.data_df.iloc[idx]['path']\n",
        "        label = int(self.data_df.iloc[idx]['dx'])\n",
        "\n",
        "        # Load image\n",
        "        img = Image.open(img_path)\n",
        "\n",
        "        # Apply transformations (if any)\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        # Ensure the image is a tensor\n",
        "        if not isinstance(img, torch.Tensor):\n",
        "            img = transforms.ToTensor()(img)\n",
        "\n",
        "        return img, label\n",
        "\n",
        "\n",
        "data_dir = '/content/dermoscopy_classification'\n",
        "transform = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor()])\n",
        "dataset = MLProject2Dataset(data_dir, transform=transform)\n",
        "\n",
        "# Example: Print the length of the dataset\n",
        "print(len(dataset))\n",
        "\n",
        "# Example: Retrieve and print the first item in the dataset\n",
        "sample_img, sample_label = dataset[0]\n",
        "print(sample_img.shape, sample_label)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUhdfNSJWSJ8",
        "outputId": "276fca62-023c-4fbb-8703-81cbb712655c"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10015\n",
            "torch.Size([3, 224, 224]) 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import random_split\n",
        "from glob import glob\n",
        "\n",
        "# Assuming you have already defined and instantiated the MLProject2Dataset class\n",
        "dataset = MLProject2Dataset(data_dir)\n",
        "\n",
        "# Seed\n",
        "seed = 42\n",
        "\n",
        "print(len(dataset))\n",
        "\n",
        "# Calculate the sizes of each split\n",
        "total_size = len(dataset)\n",
        "train_size = int(0.6 * total_size)\n",
        "val_size = int(0.1 * total_size)\n",
        "test_size = total_size - train_size - val_size\n",
        "\n",
        "# Use random_split to create train, validation, and test datasets\n",
        "train_dataset, val_dataset, test_dataset = random_split(\n",
        "    dataset,\n",
        "    lengths=[train_size, val_size, test_size],\n",
        "    generator=torch.Generator().manual_seed(seed)\n",
        ")\n",
        "\n",
        "# Print the sizes of each split\n",
        "print(f\"Train dataset size: {len(train_dataset)}\")\n",
        "print(f\"Validation dataset size: {len(val_dataset)}\")\n",
        "print(f\"Test dataset size: {len(test_dataset)}\")\n",
        "\n",
        "# create DataLoader instances for each split\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 32  # adjust this\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YipHz1cX_KUF",
        "outputId": "d963ff9f-4811-4508-dd19-d9f1b7462891"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10015\n",
            "Train dataset size: 6009\n",
            "Validation dataset size: 1001\n",
            "Test dataset size: 3005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "# Define the desired size (m, n) for resizing\n",
        "m, n = 100, 100  # Change these values\n",
        "\n",
        "# Define the transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((m, n)),  # Set m and n to desired size\n",
        "    transforms.ToTensor(),       # Convert image to Tensor\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize image\n",
        "])\n",
        "\n",
        "# Apply transformations to the dataset\n",
        "train_dataset = MLProject2Dataset(data_dir, transform=transform)\n",
        "val_dataset = MLProject2Dataset(data_dir, transform=transform)\n",
        "test_dataset = MLProject2Dataset(data_dir, transform=transform)\n",
        "\n",
        "# Create DataLoader instances for each split\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
      ],
      "metadata": {
        "id": "NZUO-Pj7eGZo"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "def calculate_accuracy(outputs, labels):\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    correct = (predicted == labels).sum().item()\n",
        "    total = labels.size(0)\n",
        "    accuracy = correct / total\n",
        "    return accuracy\n",
        "\n",
        "def train_net(model: nn.Module, trainloader: DataLoader, valloader: DataLoader = None,\n",
        "              epochs: int = 10, optimizer: optim = None, loss_fn: nn.modules.loss = None,\n",
        "              device: str = 'cpu', print_period: int = 10) -> None:\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        total_train_accuracy = 0.0\n",
        "\n",
        "        for i, data in enumerate(tqdm(trainloader, desc=f\"Epoch {epoch + 1}/{epochs}\")):\n",
        "            inputs, labels = data\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            total_train_accuracy += calculate_accuracy(outputs, labels)\n",
        "\n",
        "            if (i + 1) % print_period == 0:\n",
        "                avg_loss = running_loss / print_period\n",
        "                avg_train_accuracy = total_train_accuracy / print_period\n",
        "\n",
        "                print(f\"[Batch {i + 1}/{len(trainloader)}] Loss: {avg_loss:.4f}, Accuracy: {avg_train_accuracy:.4f}\")\n",
        "                running_loss = 0.0\n",
        "                total_train_accuracy = 0.0\n",
        "\n",
        "        if valloader is not None:\n",
        "            model.eval()\n",
        "            val_loss = 0.0\n",
        "            total_val_accuracy = 0.0\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for data in tqdm(valloader, desc=\"Validation\"):\n",
        "                    inputs, labels = data\n",
        "                    inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "                    outputs = model(inputs)\n",
        "                    val_loss += loss_fn(outputs, labels).item()\n",
        "                    total_val_accuracy += calculate_accuracy(outputs, labels)\n",
        "\n",
        "                avg_val_loss = val_loss / len(valloader)\n",
        "                avg_val_accuracy = total_val_accuracy / len(valloader)\n",
        "\n",
        "                print(f\"Epoch {epoch + 1}/{epochs}, Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {avg_val_accuracy:.4f}\")\n",
        "\n",
        "            model.train()\n",
        "\n",
        "    print(\"Training completed.\")\n"
      ],
      "metadata": {
        "id": "ItS5R9K2e7Xk"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_net(model: nn.Module, testloader: DataLoader, loss_fn: nn.modules.loss = None, device: str = 'cpu'):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    total_loss = 0.0\n",
        "    total_accuracy = 0.0\n",
        "    total_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in tqdm(testloader, desc=\"Testing\"):\n",
        "            inputs, labels = data\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_fn(outputs, labels) if loss_fn else None\n",
        "\n",
        "            total_samples += labels.size(0)\n",
        "            total_loss += loss.item() if loss is not None else 0.0\n",
        "            total_accuracy += calculate_accuracy(outputs, labels)\n",
        "\n",
        "    avg_loss = total_loss / len(testloader) if len(testloader) > 0 else None\n",
        "    avg_accuracy = total_accuracy / total_samples if total_samples > 0 else None\n",
        "\n",
        "    print(f\"Test Loss: {avg_loss:.4f}, Test Accuracy: {avg_accuracy:.4f}\")\n",
        "\n",
        "    model.train()  # Set the model back to training mode\n",
        "\n",
        "    return avg_loss, avg_accuracy\n"
      ],
      "metadata": {
        "id": "hXwcwd5egHZA"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O7gLF6H-kTFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3WqolHEVkS9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc = nn.Linear(64 * 12 * 15, 7)  # Adjust the output size\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(self.relu1(self.conv1(x)))\n",
        "        x = self.pool2(self.relu2(self.conv2(x)))\n",
        "        x = self.pool3(self.relu3(self.conv3(x)))\n",
        "        x = self.flatten(x)\n",
        "\n",
        "        # Dynamically calculate the size for the fully connected layer\n",
        "        x_size = x.size(1)\n",
        "        self.fc = nn.Linear(x_size, 7)\n",
        "\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Define the model, loss function, and optimizer\n",
        "snn_model = SimpleNN()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(snn_model.parameters(), lr=0.1)\n",
        "\n",
        "# Train the model\n",
        "train_net(model=snn_model, trainloader=train_loader, valloader=val_loader,\n",
        "          epochs=20, optimizer=optimizer, loss_fn=criterion, print_period=100)\n",
        "\n",
        "# Test the model\n",
        "test_net(model=snn_model, testloader=test_loader, loss_fn=criterion)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWS_NX0EgKFf",
        "outputId": "6522d443-7fbe-4d47-9506-297e6886c334"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/2:  32%|███▏      | 100/313 [01:19<02:45,  1.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 100/313] Loss: 1.9455, Accuracy: 0.1347\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/2:  64%|██████▍   | 200/313 [02:38<01:19,  1.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 200/313] Loss: 1.9461, Accuracy: 0.1216\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/2:  96%|█████████▌| 300/313 [03:56<00:09,  1.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 300/313] Loss: 1.9430, Accuracy: 0.1609\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/2: 100%|██████████| 313/313 [04:06<00:00,  1.27it/s]\n",
            "Validation: 100%|██████████| 313/313 [02:47<00:00,  1.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2, Validation Loss: 1.9539, Validation Accuracy: 0.1362\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/2:  32%|███▏      | 100/313 [01:23<02:47,  1.27it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 100/313] Loss: 1.9469, Accuracy: 0.1622\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/2:  64%|██████▍   | 200/313 [02:53<01:29,  1.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 200/313] Loss: 1.9474, Accuracy: 0.1344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/2:  96%|█████████▌| 300/313 [04:24<00:10,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 300/313] Loss: 1.9481, Accuracy: 0.1141\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/2: 100%|██████████| 313/313 [04:35<00:00,  1.13it/s]\n",
            "Validation: 100%|██████████| 313/313 [02:40<00:00,  1.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/2, Validation Loss: 1.9461, Validation Accuracy: 0.1573\n",
            "Training completed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 313/313 [02:47<00:00,  1.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 1.9488, Test Accuracy: 0.0043\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.9488323507979275, 0.004309161258112831)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TppmxFcEkTri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vqb6d_xtkTo-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "class ComplexCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ComplexCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
        "        self.relu4 = nn.ReLU()\n",
        "        self.bn4 = nn.BatchNorm2d(256)\n",
        "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv5 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
        "        self.relu5 = nn.ReLU()\n",
        "        self.bn5 = nn.BatchNorm2d(512)\n",
        "        self.pool5 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.global_avg_pooling = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc = nn.Linear(512, 7)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(self.bn1(self.relu1(self.conv1(x))))\n",
        "        x = self.pool2(self.bn2(self.relu2(self.conv2(x))))\n",
        "        x = self.pool3(self.bn3(self.relu3(self.conv3(x))))\n",
        "        x = self.pool4(self.bn4(self.relu4(self.conv4(x))))\n",
        "        x = self.pool5(self.bn5(self.relu5(self.conv5(x))))\n",
        "        x = self.global_avg_pooling(x)\n",
        "        x = self.flatten(x)\n",
        "\n",
        "        # Dynamically calculate the size for the fully connected layer\n",
        "        x_size = x.size(1)\n",
        "        self.fc = nn.Linear(x_size, 7)\n",
        "\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "# Define the model, loss function, and optimizer\n",
        "complex_cnn_model = ComplexCNN()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(complex_cnn_model.parameters(), lr=1e-3)\n",
        "\n",
        "# Train the model\n",
        "train_net(model=complex_cnn_model, trainloader=train_loader, valloader=val_loader,\n",
        "          epochs=2, optimizer=optimizer, loss_fn=criterion, print_period=100)\n",
        "\n",
        "# Test the model\n",
        "test_net(model=complex_cnn_model, testloader=test_loader, loss_fn=criterion)\n"
      ],
      "metadata": {
        "id": "RP0G0T95kCCr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ef3018b-2147-4174-b9f8-196aaeeb656a"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/2:  32%|███▏      | 100/313 [02:25<05:31,  1.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 100/313] Loss: 2.1319, Accuracy: 0.1341\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/2:  64%|██████▍   | 200/313 [04:42<02:25,  1.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 200/313] Loss: 2.0971, Accuracy: 0.1516\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/2:  96%|█████████▌| 300/313 [07:00<00:18,  1.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 300/313] Loss: 2.0773, Accuracy: 0.1497\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/2: 100%|██████████| 313/313 [07:18<00:00,  1.40s/it]\n",
            "Validation: 100%|██████████| 313/313 [04:00<00:00,  1.30it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2, Validation Loss: 2.0478, Validation Accuracy: 0.1397\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/2:  32%|███▏      | 100/313 [02:34<04:50,  1.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 100/313] Loss: 2.0332, Accuracy: 0.1503\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/2:  64%|██████▍   | 200/313 [05:02<02:59,  1.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 200/313] Loss: 2.0066, Accuracy: 0.1559\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/2:  96%|█████████▌| 300/313 [07:29<00:19,  1.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Batch 300/313] Loss: 2.0101, Accuracy: 0.1284\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/2: 100%|██████████| 313/313 [07:48<00:00,  1.50s/it]\n",
            "Validation: 100%|██████████| 313/313 [04:10<00:00,  1.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/2, Validation Loss: 2.0055, Validation Accuracy: 0.1488\n",
            "Training completed.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 313/313 [04:02<00:00,  1.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Loss: 2.0051, Test Accuracy: 0.0045\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2.005093669739013, 0.004515102346480279)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DNn8uYa_kRsj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LyNWPxkZkR73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.models as models\n",
        "\n",
        "# Φόρτωση του προεκπαιδευμένου μοντέλου ResNet34\n",
        "pretrained_resnet = models.resnet34(pretrained=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9oymGBGNkUaU",
        "outputId": "bd65ed85-19cb-44bc-8e30-30db280c4487"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n"
      ],
      "metadata": {
        "id": "ZTAKFAcPkXKx"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "# Δημιουργία του dataset\n",
        "dataset = MLProject2Dataset(data_dir)\n",
        "\n",
        "# Διαχωρισμός του dataset σε train, validation και test\n",
        "total_size = len(dataset)\n",
        "train_size = int(0.7 * total_size)\n",
        "val_size = int(0.15 * total_size)\n",
        "test_size = total_size - train_size - val_size\n",
        "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size], generator=torch.Generator().manual_seed(42))\n",
        "\n",
        "# Δημιουργία των dataloaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "dDsTAaaPkZ8i"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class TransferLearningModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TransferLearningModel, self).__init__()\n",
        "        # Φορτώνουμε τα βάρη του προεκπαιδευμένου ResNet34\n",
        "        self.resnet = models.resnet34(pretrained=True)\n",
        "        # Επιλέγουμε τον τύπο του επιπλέον classifier που θέλουμε\n",
        "        # (π.χ., Fully Connected Layer με 7 εξόδους για 7 κλάσεις)\n",
        "        self.fc = nn.Linear(512, 7)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.resnet(x)\n",
        "\n",
        "        # Dynamically calculate the size for the fully connected layer\n",
        "        x_size = x.size(1)\n",
        "        self.fc = nn.Linear(x_size, 7)\n",
        "\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "transfer_learning_model = TransferLearningModel()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBNx2dxekjBn",
        "outputId": "8e4c7404-6c10-47bf-c143-732f12e44b2a"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(transfer_learning_model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Εκπαίδευση για χ εποχές\n",
        "train_net(model=transfer_learning_model, trainloader=train_loader, valloader=val_loader,\n",
        "          epochs=2, optimizer=optimizer, loss_fn=criterion, print_period=100)\n",
        "\n",
        "# Αξιολόγηση στο σύνολο δοκιμής\n",
        "test_net(model=transfer_learning_model, testloader=test_loader, loss_fn=criterion)\n"
      ],
      "metadata": {
        "id": "ZHPUVF0HklZt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8861be8-56ae-4d72-c056-73b4a90a09b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/2:   7%|▋         | 16/220 [22:42<4:54:22, 86.58s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VjqReg7nCvZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pbtsmXYICvzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data_dir, metadata_fname='metadata.csv', transform=None):\n",
        "        self.data_dir = data_dir\n",
        "        self.transform = transform\n",
        "\n",
        "\n",
        "        # Load metadata\n",
        "        metadata_path = os.path.join(data_dir, metadata_fname)\n",
        "        metadata = pd.read_csv(metadata_path)\n",
        "        metadata['dx'] = pd.Categorical(metadata['dx']).codes\n",
        "\n",
        "        num_classes = metadata['dx'].nunique()\n",
        "\n",
        "        # Create dataframe with image paths and labels\n",
        "        image_paths = []\n",
        "        for part_dir in os.listdir(data_dir):\n",
        "            part_path = os.path.join(data_dir, part_dir)\n",
        "            if os.path.isdir(part_path):\n",
        "                for f in os.listdir(part_path):\n",
        "                    if f.endswith('.jpg'):\n",
        "                        image_paths.append(os.path.join(part_path, f))\n",
        "\n",
        "        image_ids = [os.path.splitext(os.path.basename(f))[0] for f in image_paths]\n",
        "\n",
        "        # Create dataframe with image paths and labels\n",
        "        image_df = pd.DataFrame({'image_id': image_ids, 'path': image_paths})\n",
        "\n",
        "        # Merge dataframes on 'image_id'\n",
        "        self.data_df = pd.merge(image_df, metadata, on='image_id')\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_df)\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.data_df.iloc[idx]['path']\n",
        "        label = int(self.data_df.iloc[idx]['dx'])\n",
        "\n",
        "        # Προσθήκη δημογραφικών χαρακτηριστικών\n",
        "        patient_info = self.data_df.iloc[idx][['age', 'gender', 'body_part']]\n",
        "        age = patient_info['age'] / 100.0  # Κανονικοποίηση της ηλικίας\n",
        "        gender = pd.get_dummies(patient_info['gender'], prefix='gender')\n",
        "        body_part = pd.get_dummies(patient_info['body_part'], prefix='body_part')\n",
        "\n",
        "        demographic_features = torch.cat([torch.tensor(age), torch.tensor(gender.values), torch.tensor(body_part.values)], dim=0)\n",
        "\n",
        "\n",
        "        img = Image.open(img_path)\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        if not isinstance(img, torch.Tensor):\n",
        "            img = transforms.ToTensor()(img)\n",
        "\n",
        "        return img, demographic_features, label\n"
      ],
      "metadata": {
        "id": "wgPPoMpLCwOK"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class DemographicModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DemographicModel, self).__init__()\n",
        "        self.linear = nn.Linear(3, 128)  # 3 demographic features, 128 outputs\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear(x)\n",
        "        x = self.relu(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "Y_a9d_tEEW0d"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CombinedModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CombinedModel, self).__init__()\n",
        "        self.simple_nn = SimpleNN()\n",
        "        self.demographic_model = DemographicModel()\n",
        "\n",
        "        # Define the final linear layer\n",
        "        final_output_size = 7\n",
        "        self.final_linear = nn.Linear(128 + final_output_size, final_output_size)\n",
        "\n",
        "    def forward(self, image, demographic_features):\n",
        "\n",
        "        # Forward pass through SimpleNN\n",
        "        x_image = self.simple_nn(image)\n",
        "\n",
        "        # Forward pass through DemographicModel\n",
        "        x_demo = self.demographic_model(demographic_features)\n",
        "\n",
        "        # Concatenate the outputs\n",
        "        x_combined = torch.cat((x_image, x_demo), dim=1)\n",
        "\n",
        "        # Final linear layer\n",
        "        x_final = self.final_linear(x_combined)\n",
        "\n",
        "        return x_final\n",
        "\n"
      ],
      "metadata": {
        "id": "iDv7XGsvC-Wl"
      },
      "execution_count": 53,
      "outputs": []
    }
  ]
}